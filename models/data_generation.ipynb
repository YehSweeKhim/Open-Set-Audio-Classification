{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "import keras\n",
    "import tensorflow\n",
    "import tensorflow_addons as tfa\n",
    "from keras import layers, Model\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = './UrbanSound8K/metadata/UrbanSound8K.csv'\n",
    "embeddings_path = \"./embeddings/\"\n",
    "model_save_path = \"data_generation\"\n",
    "test_size = 0.2\n",
    "val_size = 0.2\n",
    "batch_size = 32\n",
    "num_classes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingsLoader(keras.utils.Sequence):\n",
    "  def __init__(self, x_set, y_set, batch_size, emb_dir):\n",
    "    self.x, self.y = x_set, y_set\n",
    "    self.batch_size = batch_size\n",
    "    self.emb_dir = emb_dir\n",
    "\n",
    "  def __len__(self):\n",
    "    return int(np.ceil(len(self.x) / self.batch_size))\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    batch_x = self.x[idx * self.batch_size:(idx + 1) *\n",
    "    self.batch_size]\n",
    "    batch_y = self.y[idx * self.batch_size:(idx + 1) *\n",
    "        self.batch_size]\n",
    "\n",
    "    batchEmbs = []\n",
    "    for fileName in batch_x:\n",
    "        if fileName == \"synthetic\":\n",
    "            emb = np.random.randint(256, size=128)\n",
    "        else:\n",
    "            emb = np.load(self.emb_dir + fileName + \".npy\")[0]\n",
    "        batchEmbs.append(emb)\n",
    "    batchEmbs = np.array(batchEmbs)\n",
    "    return batchEmbs, np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(csv_path)\n",
    "data_df_known = data_df.loc[data_df[\"classID\"] < num_classes]\n",
    "data_df_unknown = data_df.loc[data_df[\"classID\"] >= num_classes]\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(data_df_known['slice_file_name'].tolist(), data_df_known['classID'].tolist(), test_size=test_size, random_state = 42)\n",
    "\n",
    "# Add synthetic data to known data\n",
    "X_trainval.extend([\"synthetic\"]*len(X_trainval))\n",
    "y_trainval.extend([num_classes]*len(y_trainval))\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=val_size, random_state = 42)\n",
    "\n",
    "# Add unknown data to test set\n",
    "X_trash, X_unknown, y_trash, y_unknown = train_test_split(data_df_unknown['slice_file_name'].tolist(), data_df_unknown['classID'].tolist(), test_size=test_size, random_state = 42)\n",
    "X_test = X_test + X_unknown\n",
    "y_test.extend([num_classes]*len(y_unknown))\n",
    "\n",
    "train_loader = EmbeddingsLoader(X_train, y_train, batch_size, embeddings_path)\n",
    "test_loader = EmbeddingsLoader(X_test, y_test, batch_size, embeddings_path)\n",
    "val_loader = EmbeddingsLoader(X_val, y_val, batch_size, embeddings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 774\n",
      "Trainable params: 774\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.InputLayer(input_shape=(128,)))\n",
    "model.add(layers.Dense(num_classes+1, activation=\"softmax\"))\n",
    "model.summary()\n",
    "model.compile(\n",
    "      optimizer=\"Adam\",\n",
    "      loss=\"sparse_categorical_crossentropy\",\n",
    "      metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "earlystopping = EarlyStopping(\n",
    "                    patience=10, \n",
    "                    restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint(\n",
    "                    model_save_path, \n",
    "                    monitor=\"val_accuracy\", \n",
    "                    save_best_only=True)\n",
    "\n",
    "model.fit(x=train_loader,\n",
    "          validation_data=val_loader,\n",
    "          callbacks=[checkpoint, earlystopping],\n",
    "          epochs=200,\n",
    "          verbose=1\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(predicted, expected):\n",
    "    acc = np.mean(np.array(predicted) == np.array(expected))\n",
    "    print(\"Overall accuracy: {}\".format(acc))\n",
    "    acc_dict = {}\n",
    "    for i in range(len(expected)):\n",
    "        expected_class = expected[i]\n",
    "        if expected_class not in acc_dict:\n",
    "            acc_dict[expected_class] = [0, 0]\n",
    "        acc_dict[expected_class][1] += 1\n",
    "        if expected_class == predicted[i]:\n",
    "            acc_dict[expected_class][0] += 1\n",
    "    for k,v in acc_dict.items():\n",
    "        print(\"Accuracy for class {}: {}\".format(k, v[0]/v[1]))\n",
    "    for average in [\"macro\", \"weighted\", \"micro\"]:\n",
    "        f1 = f1_score(expected, predicted, average=average)\n",
    "        print(\"{} f1 score: {}\".format(average, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.load_weights(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_val = model.predict_classes(x=val_loader, batch_size=None)\n",
    "predicted_test = model.predict_classes(x=test_loader, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 0.8808180535966149\n",
      "Accuracy for class 0: 0.8053691275167785\n",
      "Accuracy for class 5: 0.9763888888888889\n",
      "Accuracy for class 2: 0.8709677419354839\n",
      "Accuracy for class 3: 0.64375\n",
      "Accuracy for class 4: 0.8164556962025317\n",
      "Accuracy for class 1: 0.7763157894736842\n",
      "macro f1 score: 0.8244368958493468\n",
      "weighted f1 score: 0.8796253816023716\n",
      "micro f1 score: 0.8808180535966149\n",
      "Overall accuracy: 0.45163136805953064\n",
      "Accuracy for class 2: 0.8423645320197044\n",
      "Accuracy for class 4: 0.8546511627906976\n",
      "Accuracy for class 0: 0.7751196172248804\n",
      "Accuracy for class 3: 0.6447368421052632\n",
      "Accuracy for class 1: 0.7837837837837838\n",
      "Accuracy for class 5: 0.1207897793263647\n",
      "macro f1 score: 0.5056223889884606\n",
      "weighted f1 score: 0.3898216489817824\n",
      "micro f1 score: 0.45163136805953064\n"
     ]
    }
   ],
   "source": [
    "evaluate(predicted_val, y_val)\n",
    "evaluate(predicted_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
