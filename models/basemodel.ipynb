{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import layers, Model\n",
    "from keras.models import Sequential\n",
    "from keras.applications import DenseNet201\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = './UrbanSound8K/metadata/UrbanSound8K.csv'\n",
    "spectrograms_path = \"./numpySpectrograms/\"\n",
    "model_save_path = \"basemodel-known\"\n",
    "test_size = 0.2\n",
    "val_size = 0.2\n",
    "batch_size = 16\n",
    "num_classes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecLoader(keras.utils.Sequence):\n",
    "  def __init__(self, x_set, y_set, batch_size, spec_dir):\n",
    "    self.x, self.y = x_set, y_set\n",
    "    self.batch_size = batch_size\n",
    "    self.spec_dir = spec_dir\n",
    "\n",
    "  def __len__(self):\n",
    "    return int(np.ceil(len(self.x) / self.batch_size))\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    batch_x = self.x[idx * self.batch_size:(idx + 1) *\n",
    "    self.batch_size]\n",
    "    batch_y = self.y[idx * self.batch_size:(idx + 1) *\n",
    "        self.batch_size]\n",
    "\n",
    "    batchSpecs = []\n",
    "    for fileName in batch_x:\n",
    "        spec = np.load(self.spec_dir + fileName + \".npy\")\n",
    "        batchSpecs.append(spec.transpose())\n",
    "    return np.array(batchSpecs), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(csv_path)\n",
    "data_df_known = data_df.loc[data_df[\"classID\"] < 5]\n",
    "data_df_unknown = data_df.loc[data_df[\"classID\"] >= 5]\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(data_df_known['slice_file_name'].tolist(), data_df_known['classID'].tolist(), test_size=test_size, random_state = 42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=val_size, random_state = 42)\n",
    "X_trash, X_unknown, y_trash, y_unknown = train_test_split(data_df_unknown['slice_file_name'].tolist(), data_df_unknown['classID'].tolist(), test_size=test_size, random_state = 42)\n",
    "y_unknown = [-1] * len(y_unknown)\n",
    "\n",
    "X_known_test = X_test\n",
    "y_known_test = y_test\n",
    "known_test_loader = SpecLoader(X_test, y_test, batch_size, spectrograms_path)\n",
    "X_test = X_test + X_unknown\n",
    "y_test = y_test + y_unknown\n",
    "train_loader = SpecLoader(X_train, y_train, batch_size, spectrograms_path)\n",
    "test_loader = SpecLoader(X_test, y_test, batch_size, spectrograms_path)\n",
    "val_loader = SpecLoader(X_val, y_val, batch_size, spectrograms_path)\n",
    "trainval_loader = SpecLoader(X_trainval, y_trainval, batch_size, spectrograms_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet201 (Model)          (None, 1920)              18321984  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 9605      \n",
      "=================================================================\n",
      "Total params: 18,331,589\n",
      "Trainable params: 18,102,533\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "densenet = DenseNet201(\n",
    "            include_top=False,\n",
    "            weights=\"imagenet\",\n",
    "            input_tensor=None,\n",
    "            input_shape=None,\n",
    "            pooling=\"avg\")\n",
    "model = Sequential()\n",
    "model.add(densenet)\n",
    "model.add(layers.Dense(num_classes, activation=\"softmax\"))\n",
    "model.summary()\n",
    "model.compile(\n",
    "      optimizer=\"Adam\",\n",
    "      loss=\"sparse_categorical_crossentropy\",\n",
    "      metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "178/178 [==============================] - 180s 1s/step - loss: 0.7785 - accuracy: 0.7382 - val_loss: 15.3976 - val_accuracy: 0.4118\n",
      "Epoch 2/70\n",
      "178/178 [==============================] - 50s 283ms/step - loss: 0.4679 - accuracy: 0.8483 - val_loss: 0.1058 - val_accuracy: 0.8688\n",
      "Epoch 3/70\n",
      "178/178 [==============================] - 50s 283ms/step - loss: 0.3411 - accuracy: 0.8800 - val_loss: 0.0637 - val_accuracy: 0.8858\n",
      "Epoch 4/70\n",
      "178/178 [==============================] - 51s 285ms/step - loss: 0.2386 - accuracy: 0.9143 - val_loss: 0.3492 - val_accuracy: 0.8632\n",
      "Epoch 5/70\n",
      "178/178 [==============================] - 50s 282ms/step - loss: 0.2107 - accuracy: 0.9255 - val_loss: 0.0042 - val_accuracy: 0.9055\n",
      "Epoch 6/70\n",
      "178/178 [==============================] - 50s 283ms/step - loss: 0.1638 - accuracy: 0.9425 - val_loss: 0.0363 - val_accuracy: 0.8463\n",
      "Epoch 7/70\n",
      "178/178 [==============================] - 50s 282ms/step - loss: 0.1407 - accuracy: 0.9499 - val_loss: 0.0743 - val_accuracy: 0.9351\n",
      "Epoch 8/70\n",
      "178/178 [==============================] - 50s 282ms/step - loss: 0.0911 - accuracy: 0.9718 - val_loss: 0.0056 - val_accuracy: 0.9436\n",
      "Epoch 9/70\n",
      "178/178 [==============================] - 50s 283ms/step - loss: 0.1305 - accuracy: 0.9541 - val_loss: 0.0033 - val_accuracy: 0.9295\n",
      "Epoch 10/70\n",
      "178/178 [==============================] - 50s 282ms/step - loss: 0.1176 - accuracy: 0.9587 - val_loss: 0.1584 - val_accuracy: 0.9097\n",
      "Epoch 11/70\n",
      "178/178 [==============================] - 50s 282ms/step - loss: 0.0422 - accuracy: 0.9873 - val_loss: 0.0032 - val_accuracy: 0.9549\n",
      "Epoch 12/70\n",
      "178/178 [==============================] - 50s 282ms/step - loss: 0.0619 - accuracy: 0.9799 - val_loss: 2.2625e-05 - val_accuracy: 0.9027\n",
      "Epoch 13/70\n",
      "178/178 [==============================] - 50s 282ms/step - loss: 0.1418 - accuracy: 0.9555 - val_loss: 0.0625 - val_accuracy: 0.8166\n",
      "Epoch 14/70\n",
      "178/178 [==============================] - 50s 282ms/step - loss: 0.0328 - accuracy: 0.9912 - val_loss: 2.7950e-04 - val_accuracy: 0.9408\n",
      "Epoch 15/70\n",
      "178/178 [==============================] - 50s 281ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.0032 - val_accuracy: 0.9224\n",
      "Epoch 16/70\n",
      "178/178 [==============================] - 50s 281ms/step - loss: 0.1188 - accuracy: 0.9566 - val_loss: 0.5489 - val_accuracy: 0.8110\n",
      "Epoch 17/70\n",
      "178/178 [==============================] - 50s 281ms/step - loss: 0.0475 - accuracy: 0.9845 - val_loss: 0.0064 - val_accuracy: 0.9520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fa9296f6fd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystopping = EarlyStopping(\n",
    "                    patience=5, \n",
    "                    restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint(\n",
    "                    model_save_path, \n",
    "                    monitor=\"val_accuracy\", \n",
    "                    save_best_only=True)\n",
    "\n",
    "model.fit(x=train_loader,\n",
    "          validation_data=val_loader,\n",
    "          callbacks=[checkpoint, earlystopping],\n",
    "          epochs=70,\n",
    "          verbose=1\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(predicted, expected):\n",
    "    acc = np.mean(np.array(predicted) == np.array(expected))\n",
    "    print(\"Overall accuracy: {}\".format(acc))\n",
    "    acc_dict = {}\n",
    "    for i in range(len(expected)):\n",
    "        expected_class = expected[i]\n",
    "        if expected_class not in acc_dict:\n",
    "            acc_dict[expected_class] = [0, 0]\n",
    "        acc_dict[expected_class][1] += 1\n",
    "        if expected_class == predicted[i]:\n",
    "            acc_dict[expected_class][0] += 1\n",
    "    for k,v in acc_dict.items():\n",
    "        print(\"Accuracy for class {}: {}\".format(k, v[0]/v[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(model_save_path)\n",
    "# test_loss, test_accuracy= model.evaluate(x=known_test_loader)\n",
    "y_predicted = model.predict_classes(x=known_test_loader, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 0.945823927765237\n",
      "Accuracy for class 2: 0.9359605911330049\n",
      "Accuracy for class 4: 0.9651162790697675\n",
      "Accuracy for class 0: 0.9856459330143541\n",
      "Accuracy for class 3: 0.8947368421052632\n",
      "Accuracy for class 1: 0.972972972972973\n",
      "0.9505503979575508\n",
      "0.9456365533255318\n",
      "0.945823927765237\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_predicted, y_known_test)\n",
    "for average in [\"macro\", \"weighted\", \"micro\"]:\n",
    "    f1 = f1_score(y_known_test, y_predicted, average=average)\n",
    "    print(f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
