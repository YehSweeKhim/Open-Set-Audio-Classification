{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "import keras\n",
    "import tensorflow\n",
    "import tensorflow_addons as tfa\n",
    "from keras import layers, Model\n",
    "from keras.models import Sequential\n",
    "from keras.applications import DenseNet201\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = './UrbanSound8K/metadata/UrbanSound8K.csv'\n",
    "spec_path = \"./numpySpectrograms/\"\n",
    "test_size = 0.2\n",
    "val_size = 0.2\n",
    "batch_size = 16\n",
    "num_classes = 5\n",
    "target_class = 4\n",
    "model_save_path = \"ovr_basemodel\" + str(target_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecLoader(keras.utils.Sequence):\n",
    "  def __init__(self, x_set, y_set, batch_size, spec_dir):\n",
    "    self.x, self.y = x_set, y_set\n",
    "    self.batch_size = batch_size\n",
    "    self.spec_dir = spec_dir\n",
    "\n",
    "  def __len__(self):\n",
    "    return int(np.ceil(len(self.x) / self.batch_size))\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    batch_x = self.x[idx * self.batch_size:(idx + 1) *\n",
    "    self.batch_size]\n",
    "    batch_y = self.y[idx * self.batch_size:(idx + 1) *\n",
    "        self.batch_size]\n",
    "\n",
    "    batchSpecs = []\n",
    "    for fileName in batch_x:\n",
    "        spec = np.load(self.spec_dir + fileName + \".npy\")\n",
    "        batchSpecs.append(spec.transpose())\n",
    "    return np.array(batchSpecs), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(csv_path)\n",
    "data_df_known = data_df.loc[data_df[\"classID\"] < num_classes]\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(data_df_known['slice_file_name'].tolist(), data_df_known['classID'].tolist(), test_size=test_size, random_state = 42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=val_size, random_state = 42)\n",
    "\n",
    "y_train = [1 if j == target_class else 0 for j in y_train]\n",
    "y_val = [1 if j == target_class else 0 for j in y_val]\n",
    "y_test = [1 if j == target_class else 0 for j in y_test]\n",
    "\n",
    "train_loader = SpecLoader(X_train, y_train, batch_size, spec_path)\n",
    "val_loader = SpecLoader(X_val, y_val, batch_size, spec_path)\n",
    "test_loader = SpecLoader(X_test, y_test, batch_size, spec_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet201 (Model)          (None, 1920)              18321984  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 3842      \n",
      "=================================================================\n",
      "Total params: 18,325,826\n",
      "Trainable params: 18,096,770\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "densenet = DenseNet201(\n",
    "            include_top=False,\n",
    "            weights=\"imagenet\",\n",
    "            input_tensor=None,\n",
    "            input_shape=None,\n",
    "            pooling=\"avg\")\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(densenet)\n",
    "model.add(layers.Dense(2, activation=\"softmax\"))\n",
    "model.summary()\n",
    "model.compile(\n",
    "      optimizer=\"Adam\",\n",
    "      loss=\"sparse_categorical_crossentropy\",\n",
    "      metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "178/178 [==============================] - 192s 1s/step - loss: 0.3259 - accuracy: 0.8913 - val_loss: 3.8005 - val_accuracy: 0.6474\n",
      "Epoch 2/70\n",
      "178/178 [==============================] - 53s 297ms/step - loss: 0.1847 - accuracy: 0.9273 - val_loss: 0.2555 - val_accuracy: 0.8815\n",
      "Epoch 3/70\n",
      "178/178 [==============================] - 53s 296ms/step - loss: 0.1597 - accuracy: 0.9439 - val_loss: 0.0975 - val_accuracy: 0.9069\n",
      "Epoch 4/70\n",
      "178/178 [==============================] - 53s 296ms/step - loss: 0.1128 - accuracy: 0.9577 - val_loss: 0.3626 - val_accuracy: 0.9506\n",
      "Epoch 5/70\n",
      "178/178 [==============================] - 52s 295ms/step - loss: 0.0933 - accuracy: 0.9647 - val_loss: 0.0140 - val_accuracy: 0.9549\n",
      "Epoch 6/70\n",
      "178/178 [==============================] - 52s 295ms/step - loss: 0.0699 - accuracy: 0.9728 - val_loss: 0.1126 - val_accuracy: 0.9281\n",
      "Epoch 7/70\n",
      "178/178 [==============================] - 53s 298ms/step - loss: 0.1079 - accuracy: 0.9615 - val_loss: 0.0790 - val_accuracy: 0.9351\n",
      "Epoch 8/70\n",
      "178/178 [==============================] - 54s 301ms/step - loss: 0.0652 - accuracy: 0.9757 - val_loss: 0.0293 - val_accuracy: 0.9408\n",
      "Epoch 9/70\n",
      "178/178 [==============================] - 54s 301ms/step - loss: 0.0483 - accuracy: 0.9838 - val_loss: 0.8210 - val_accuracy: 0.8731\n",
      "Epoch 10/70\n",
      "178/178 [==============================] - 52s 294ms/step - loss: 0.1468 - accuracy: 0.9492 - val_loss: 7.0162 - val_accuracy: 0.7743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f81ff674cc0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystopping = EarlyStopping(\n",
    "                    patience=5, \n",
    "                    restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint(\n",
    "                    model_save_path, \n",
    "                    monitor=\"val_accuracy\", \n",
    "                    save_best_only=True)\n",
    "\n",
    "model.fit(x=train_loader,\n",
    "          validation_data=val_loader,\n",
    "          callbacks=[checkpoint, earlystopping],\n",
    "          epochs=70,\n",
    "          verbose=1\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.load_weights(model_save_path)\n",
    "y_predicted = model.predict_classes(x=test_loader, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 12s 65ms/step\n",
      "[0.0009712110040709376, 0.9657727479934692]\n",
      "45/45 [==============================] - 3s 65ms/step\n",
      "[0.01401529274880886, 0.9548659920692444]\n",
      "56/56 [==============================] - 4s 65ms/step\n",
      "[0.061140093952417374, 0.9525959491729736]\n",
      "Overall accuracy: 0.9525959367945824\n",
      "Accuracy for class 0: 0.9551820728291317\n",
      "Accuracy for class 1: 0.9418604651162791\n"
     ]
    }
   ],
   "source": [
    "def evaluate(predicted, expected):\n",
    "    acc = np.mean(np.array(predicted) == np.array(expected))\n",
    "    print(\"Overall accuracy: {}\".format(acc))\n",
    "    acc_dict = {}\n",
    "    for i in range(len(expected)):\n",
    "        expected_class = expected[i]\n",
    "        if expected_class not in acc_dict:\n",
    "            acc_dict[expected_class] = [0, 0]\n",
    "        acc_dict[expected_class][1] += 1\n",
    "        if expected_class == predicted[i]:\n",
    "            acc_dict[expected_class][0] += 1\n",
    "    for k,v in acc_dict.items():\n",
    "        print(\"Accuracy for class {}: {}\".format(k, v[0]/v[1]))\n",
    "\n",
    "print(model.evaluate(x=train_loader))\n",
    "print(model.evaluate(x=val_loader))\n",
    "print(model.evaluate(x=test_loader))\n",
    "evaluate(y_predicted, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
